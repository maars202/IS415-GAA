---
title: "Take Home Exercise 2"
author: "Maaruni"
execute: 
  warning: false
date: 02/09/2024
editor: 
  markdown: 
    wrap: sentence
---

# Overview

## Setting the Scene

Dengue Hemorrhagic Fever (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions.
It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes.
In 2015, Taiwan had recorded the most severe dengue fever outbreak with more than 43,000 dengue cases and 228 deaths.
Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases.
However, in 2023, Taiwan recorded 26703 dengue fever cases.
Figure below reveals that more than 25,000 cases were reported at Tainan City.

Figure 2 and 3 below reveal that more than 80% of the reported dengue fever cases occurred in the month August-November 2023 and epidemiology week 31-50.

## Objectives

As a curious geospatial analytics green horn, you are interested to discover:

if the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from space and space and time.
If the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.

## The Task

The specific tasks of this take-home exercise are as follows:

Using appropriate function of sf and tidyverse, preparing the following geospatial data layer: a study area layer in sf polygon features.
It must be at village level and confined to the D01, D02, D04, D06, D07, D08, D32 and D39 counties of Tainan City, Taiwan.
a dengue fever layer within the study area in sf point features.
The dengue fever cases should be confined to epidemiology week 31-50, 2023.
a derived dengue fever layer in spacetime s3 class of sfdep.
It should contain, among many other useful information, a data field showing number of dengue fever cases by village and by epidemiology week.
Using the extracted data, perform global spatial autocorrelation analysis.
Using the extracted data, perform local spatial autocorrelation analysis.
Using the extracted data, perform emerging hotspot analysis.
Describe the spatial patterns revealed by the analysis above.

## The Data

For the purpose of this take-home exercise, two data sets are provided, they are:

TAIWAN_VILLAGE_2020, a geospatial data of village boundary of Taiwan.
It is in ESRI shapefile format.
The data is in Taiwan Geographic Coordinate System.
(Source: Historical map data of the village boundary: TWD97 longitude and latitude)

Dengue_Daily.csv, an aspatial data of reported dengue cases in Taiwan since 1998.
(Source: Dengue Daily Confirmed Cases Since 1998. Below are selected fields that are useful for this study:

發病日: Onset date 最小統計區中心點X: x-coordinate 最小統計區中心點Y: y-coordinate Both data sets have been uploaded on eLearn.
Students are required to download them from eLearn.

# Getting Started

## Data Acquisition

|                                |                                                                           |
|----------------------|--------------------------------------------------|
| [**Dataset Name**]{.underline} | [**Source**]{.underline}                                                  |
| TAIWAN_VILLAGE_2020            | Historical map data of the village boundary: TWD97 longitude and latitude |
| Dengue_Daily.csv               | Dengue Daily Confirmed Cases Since 1998                                   |

## Installing and Loading Packages

Lets install the relevant R libraries needed using pacman.

```{r}
pacman::p_load(sf, spNetwork, tmap, classInt, viridis, tidyverse, list, arrow, lubridate, tidyverse, readr, sp, maptools, raster, spatstat, spdep, readr, ggplot2, plotly, hexbin, gganimate, gifski, png, transformr, dplyr, spacetime)
```

### Setting Important Configurations

```{r}
#| eval: false
folderToSave <- "/Users/maarunipandithurai/Documents/maars202/geospatial/IS415-GAA/data/rds"
```

```{r}
#| eval: false
currentdirec = list.files(path="../../data/takehomeassigment2/geospatial", pattern=NULL, all.files=FALSE, 
    full.names=FALSE)
currentdirec
```

Reading the grab aspatial data:

```{r}
#| eval: false
dengue_df <- read_csv("../../data/takehomeassigment2/aspatial/Dengue_Daily.csv")
dengue_df
```

Getting Columns of dengue_df:

```{r}
#| eval: false
names(dengue_df)
```

Lets print a summary of dengue_df to find the data distribution and other info:

```{r}
#| eval: false
summary(dengue_df[])
```

We need to retrieve the coastal outline of Taiwan village so that we are able to fetch the dengue infections specifically within these boundaries.

```{r}
#| eval: false
taiwan_sf <- st_read(dsn = "../../data/takehomeassigment2/geospatial", layer="TAINAN_VILLAGE") %>% 
  st_transform(crs = 3826)
taiwan_sf
```

```{r}
#| eval: false
plot(taiwan_sf)
```

According to <https://epsg.io/3826>, the EPSG code for taiwan to be used as the coordinate system is 3826.
Thus, the data has been projected to Taiwan's coordinate system using 3826.

```{r}
#| eval: false
# find location of missing values
print("Position of missing values ")
which(is.na(dengue_df))
 
# count total missing values 
print("Count of total missing values  ")
sum(is.na(dengue_df))


colSums(is.na(dengue_df))
```

::: callout-tip
Interesting observation I had here was how all the columns had no missing values and yet the map was not being plotted.
Then, I realised it was due to the null values being presented as "None" string instead of the numerical value such as the example below.
:::

```{r}
#| eval: false
dengue_df[6,]$最小統計區中心點X
```

Lets filter out all the None values to get valid x and y coordinates.
最小統計區中心點X, 最小統計區中心點Y

```{r}
#| eval: false
dengue_df_filtered <- filter(dengue_df, 最小統計區中心點X != "None" & 最小統計區中心點Y != "None")
head(dengue_df_filtered)
```

|     |
|-----|
|     |
|     |

filter by epiweek 31 to 50 in 2023 - <https://www.cmmcp.org/sites/g/files/vyhlif2966/f/uploads/epiweekcalendar2023.pdf>

```{r}
#| eval: false
dengue_df_filtered$epiweek = epiweek(dengue_df_filtered$發病日)
names(dengue_df_filtered)
```

```{r}
#| eval: false
start_date = "2023-07-30"
end_date = "2023-12-16"
dengue_df_filtered = filter(dengue_df_filtered, 發病日 >= start_date & 發病日 <= end_date)
dengue_df_filtered
```

todo: After filtering valid points, lets convert the latitude and longitude from TWD97 to wsg84 as it conforms to google maps and most global standards for easier analysis.

<!--#  3826 https://epsg.io/transform#s_srs=3826&t_srs=4326&ops=3830&x=NaN&y=NaN -->

```{r}
#| eval: false
dengue_df_filtered <- st_as_sf(dengue_df_filtered, 
                       coords = c("最小統計區中心點X","最小統計區中心點Y"),
                       crs=3826) %>%
st_transform(crs = 3826)
glimpse(dengue_df_filtered)
```

```{r}
#| eval: false
tmap_mode('view')
tm_shape(dengue_df_filtered[1:100,])+
 tm_dots()
```

最小統計區中心點X, 最小統計區中心點Y

Let us save this combined dataframe to RDS so that we will not need to repeat the above steps.
Replace filepath with the directory you would like to save the rds at.

```{r}
#| eval: false
filepath <- str_interp("${folderToSave}/dengue_df")
write_rds(dengue_df_filtered, filepath) 
```

Continue from here for subsequent steps:

```{r}
#| eval: false
filepath <- str_interp("${folderToSave}/dengue_df")
dengue_df <- read_rds(filepath, refhook = NULL)
head(dengue_df) 
```

# Analysis

```{r}
pacman::p_load(sf, sfdep, spNetwork, tmap, classInt, viridis, tidyverse, list, arrow, lubridate, tidyverse, readr, sp, maptools, raster, spatstat, spdep, readr, ggplot2, plotly, hexbin, gganimate, gifski, png, transformr, dplyr)
folderToSave <- "/Users/maarunipandithurai/Documents/maars202/geospatial/IS415-GAA/data/rds"
```

```{r}
taiwan_sf <- st_read(dsn = "../../data/takehomeassigment2/geospatial", layer="TAINAN_VILLAGE")
head(taiwan_sf)
```

```{r}
filepath <- str_interp("${folderToSave}/dengue_df")
dengue_df <- read_rds(filepath, refhook = NULL)
head(dengue_df) 
```

Columns in dengue_df:

```{r}
names(dengue_df)
#感染縣市
```

```{r}
names(dengue_df)[1] = "Day_of_onset"
names(dengue_df)[2] = "Day_of_judgement"
names(dengue_df)[3] = "Day_of_report"
names(dengue_df)[4] = "Gender"
names(dengue_df)[5] = "Age_group"

names(dengue_df)[6] = "County_and_city_of_residence"
names(dengue_df)[7] = "TOWNNAME"
names(dengue_df)[8] = "VILLNAME"
names(dengue_df)[9] = "Minimum_statistical_area"
names(dengue_df)[10] = "First_level_statistical_area"

names(dengue_df)[11] = "Secondary_level_statistical_area"
names(dengue_df)[12] = "Infected_counties_and_cities"
names(dengue_df)[13] = "Infected_towns"
names(dengue_df)[14] = "Infect_the_village"
names(dengue_df)[15] = "Whether_to_immigrate_from_abroad"

names(dengue_df)[16] = "Infected_countries"
names(dengue_df)[17] = "Number_of_cases"
names(dengue_df)[18] = "Residential_village_code"
names(dengue_df)[19] = "Infected_Village_Code"
names(dengue_df)[20] = "Serotype"

names(dengue_df)[21] = "Ministry_of_Interior_county"
names(dengue_df)[22] = "Home_Office_Township_Code_of_Residence"
names(dengue_df)[23] = "Ministry_of_Interior"
names(dengue_df)[24] = "Home_Office_Infection_Township_Code"
```

## Data distribution for columns

::: panel-tabset
#### Age

```{r}
#| eval: false
g <- ggplot(dengue_df_2, aes(年齡層))  
p <-  g + geom_bar() + ggtitle("Count of Entries by Age") +  xlab("Age") + ylab("Count")

ggplotly(p) 
```

#### Infected_counties_and_cities

```{r}
#| eval: false
g <- ggplot(dengue_df, aes(Infected_counties_and_cities))  
p <-  g + geom_bar() + ggtitle("Count of Entries by 感染縣市") +  xlab("Infected_counties_and_cities") + ylab("Count")

ggplotly(p) 


ggplotly(p)

```

\
:::

```{r}
#plots will be done later due to time constraints
#plot(dengue_df)
```

only need county codes:

```{r}
taiwan_sf_filtered <- filter(taiwan_sf, TOWNID %in% c('D01', 'D02', 'D04', 'D06', 'D07', 'D08', 'D32', 'D39'))
head(taiwan_sf_filtered)
```

recode chinese column names to enlgish

```{r}
names(taiwan_sf_filtered)
```

group by village town and week to get the count according to week and region

```{r}
dengue_df_count = dengue_df %>% group_by(VILLNAME, TOWNNAME, epiweek) %>%
  summarise(total_count = n())

dengue_df_count = st_drop_geometry(dengue_df_count)
head(dengue_df_count)
```

maybe can save here:

```{r}
dengue_df_count$VILLTOWN = paste(dengue_df_count$VILLNAME, dengue_df_count$TOWNNAME)
taiwan_sf_filtered$VILLTOWN = paste(taiwan_sf_filtered$VILLNAME, taiwan_sf_filtered$TOWNNAME)
```

```{r}
dengue_df_count2 = dengue_df_count %>%
            ungroup() %>%
  select(3,4, 5) 
names(dengue_df_count2)[1] = "epiweek"
head(dengue_df_count2)
```

Before adding in entries for missing observations in taiwan sf, lets observe how it initially looks like:

![](vacrate.gif)

As we can see there are many missing regions with no observations according to dengue_df.
We need to creating empty observations with count 0 so that we are able to create the spacetime cube later for spatiotemporal analysis.

```{r}
#dengue_df_distribution
#dengue_df_combined
#for each town check if the week exists is not then add row for that week for that reach with count 0 
# VILLTOWN epiweek total_count                       geometry
total_invalids = 0
for(i in 1:nrow(taiwan_sf_filtered))
{
  region = taiwan_sf_filtered$VILLTOWN[i]
  #cat("region: ", region)
  for(j in 31:50){
    if (nrow(dengue_df_count2[dengue_df_count2$epiweek == j & dengue_df_count2$VILLTOWN == region, ]) == 0){
    matching_week_region = c(epiweek = j, total_count = 0, VILLTOWN = region)
    dengue_df_count2 = rbind(dengue_df_count2,matching_week_region) 
    total_invalids = total_invalids + 1
    }
  }
  #print(total_invalids)
}
print(total_invalids)
```

left join to aspatial data to add the attributes of aspatial to regions

```{r}
dengue_df_combined = left_join(taiwan_sf_filtered, dengue_df_count2)
dengue_df_combined <- dengue_df_combined %>%
  select(11, 12, 13)
names(dengue_df_combined)[2] = "epiweek"
head(dengue_df_combined)
```

dont run this

```{r}
dengue_df_distribution = dengue_df_combined %>% group_by(VILLTOWN) %>%
  summarise(total_count_weeks = n())
dengue_df_distribution
```

Plotting distributions of all the ???

```{r}
week33 = dengue_df_combined[dengue_df_combined$epiweek == 33, ]
#week33
tmap_mode("plot")
tm_shape(week33) +
  tm_fill("total_count") +
  tm_borders()
```

```{r}
vacrate_anim <-
  tm_shape(dengue_df_combined) + tm_fill("total_count",
            palette = "Greens") +
    tm_borders(lwd = 0.1) +
  tm_facets(along = "epiweek", free.coords = FALSE)
```

```{r}
vacrate_anim
```

```{r}
tmap_animation(vacrate_anim, filename = "vacrate2.gif", delay = 100, width = 1280, height = 720, scale = 2)
```

![](vacrate2.gif)

```{r}
dengue_df_combined_withgeometry = dengue_df_combined
dengue_df_combined = st_drop_geometry(dengue_df_combined)
head(dengue_df_combined)
```

```{r}
dengue_df_combined['epiweek'] <- as.integer(unlist(dengue_df_combined['epiweek']))
dengue_df_combined['total_count'] <- as.integer(unlist(dengue_df_combined['total_count']))
head(dengue_df_combined)
```

```{r}
bos = spacetime(dengue_df_combined, taiwan_sf_filtered,
                .loc_col = "VILLTOWN",
                .time_col = "epiweek")
head(bos)
```

```{r}
is_spacetime_cube(bos)
```

```{r}
dengue_nb <- bos %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")
```

```{r}
head(dengue_nb)
```

```{r}
#gi_stars <- dengue_nb %>% 
#  group_by(epiweek) %>% 
#  mutate(gi_star = local_gstar_perm(
#    total_count, nb, wt)) %>% 
#  tidyr::unnest(gi_star)


```

These are towns with no observations.
However, since they exist as neighbors of other cities we need to add dummy observations for all the weeks for each of these towsn as well to get 258 \* 20 = 5160 observations for spacetime cube later:

```{r}
cat("neighbors of region 1: ")
print( dengue_nb[1, ]$nb)
cat("neighbors of region 6: ")
print( dengue_nb[6, ]$nb)

cat("neighbors of region 118: ")
print( dengue_nb[118, ]$nb)
cat("neighbors of region 118: ")
print( dengue_nb[118, ]$nb)
```

## **Computing Gi\***

isolating only one week :

```{r}
dengue_nb_week31 = filter(dengue_nb, dengue_nb$epiweek == 31)
head(dengue_nb_week31)
```

some of them have no neighbors

```{r}
lengths(dengue_nb_week31[1, ]$nb)
```

```{r}
dengue_nb_week31[187, ]$nb
lengths(dengue_nb_week31[187, ]$nb)
print("--------------")
#card(dengue_nb_week31[1, ]$nb[1])
print("--------------")
#card(dengue_nb_week31[187, ]$nb)

```

```{r}
#gi_star = local_gstar_perm( dengue_nb_week31, dengue_nb_week31$nb, dengue_nb_week31$wt)
```

method 2

```{r}
#wm_idw <- dengue_df_combined %>%
#  mutate(nb = st_contiguity(geometry),
#         wts = st_inverse_distance(nb, geometry,
#                                   scale = 1,
#                                   alpha = 1),
#         .before = 1)
```

this might be useful for points that have missing towns:

```         
left_join(dfx, dfy, join_by(closest(a < b))) # similar to above, but only take the closest match
```

::: callout-note
Planning:

-   use statistical means to get distribution and see which one best - identify unique patterns and write reflection on them

<!-- -->

-   add the cold and hot spots as separate layers for users to interact with

-   facet plots

-   make ranges for plots similar when comparing plots side by side
:::

# References

-   <https://r4gdsa.netlify.app/chap04.html>

-   <https://r4gdsa.netlify.app/chap07.html>
