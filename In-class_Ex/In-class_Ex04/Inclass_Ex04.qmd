---
title: "In Class Exercise 4"
author: "Maaruni"
execute: 
  warning: false
date: 01/29/2024
date-modified: "`r Sys.Date()`"
---

# In Class Exercise 4

-   GWmodel: for calibrating statistical models by explicitly incorporating weights - it doesnt use contiguity

    -   provides collection of distance matrix to calculate some statistical analysis, multivariate statistics such as principle component analysis (PCA) and logistic regression, etc.

    -   We are going to do summary statistics analysis - aggregation functions such as sum, average

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)
```

Import Data:

```{r}
hunan <- st_read(dsn = "../../data/geospatial", 
                 layer = "Hunan")

hunan2012 <- read_csv("../../data/aspatial/Hunan_2012.csv", show_col_types = FALSE)
```

```{r}
hunan <- left_join(hunan, hunan2012) %>%
select (1:4, 7, 15)
```

Currently hunan variable in sf. As an older library, gwmodel only accepts spatial data. So we need to convert from sf to spatial data.

```{r}
hunan_sp <- hunan %>%
  as_Spatial()
```

```{r}
gwstat <- gwss(data = hunan_sp, vars = "GDPPC", bw = 6, kernel = "bisquare", adaptive = TRUE, longlat = T)
```

Since adaptive = True, we need to specify the number of neighbors using bw = 6. If adaptive = False, we need to specify bw as the fixed distance needed to capture any number of neighbors within that distance. "bisquare" for kernel is similar to what we learnt in class slides like the formula.

gwstat variable is saved in SDF object where it gives **summary statistics** of data and selecting 'data' key in SDF object shows you the data table. GDPPC_LM is based on **distance metrics instead of contiguity metrics** which is based on spatial window sum as discussed in the slides.

### Homework 

Plot similar to spatial window sum plots

-   GDPPC_LM

-   GDPPC_LSD

-   LVar

-   LSKe

-   LCV

# Revision of Hands On Exercise 4

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```

```{r}
hunan <- st_read(dsn = "../../data/geospatial", 
                 layer = "Hunan")

hunan2012 <- st_read("../../data/aspatial/Hunan_2012.csv")
```

```{r}
hunan <- left_join(hunan, hunan2012) %>%
select (1:4, 7, 15)
```

Note: if no "by" field is detected, it will automatically choose the column that both tables share. Total number of columsn will be 36 = 29 + 8 - 1.

Keep the most important columns and drop the rest. This should be similar to pd.drop(columns = \['name1'..\]).

```{r}
basemap <- tm_shape(hunan) + tm_polygons() + tm_text("NAME_3", size = 0.5)
gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp = 1, ncol = 2)
```

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

```{r}
wm_q[[1]]
```

```{r}
hunan$County[1]
```

```{r}
hunan$NAME_3[c(2,3,4,57,85)]
```

### **CREATING (ROOK) CONTIGUITY BASED NEIGHBOURS**

The code chunk below is used to compute Rook contiguity weight matrix.

```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```

Useful to compare it by plotting it.

Need to see what lines are present in the queen continuity that are not present in the rook continuity? Queen method should have more lines since it explores closest 8 neighbors while rook only explores 4 neighbors!

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```

```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```

Recalling from lesson 1: Polygon is made of points in the form . Get only the centroid to get the central component:

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Warning: Dont sort the dataset since it will make the function miss out the true centroid!

Combine them together:

```{r}
coords <- cbind(longitude, latitude)
```

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="Queen Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
plot(hunan$geometry, border="lightgrey", main="Rook Contiguity")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
```

knearneigh - didnt specific how many neighbors we are looking at. So how will it know which closest neighbors to take?

```{r}
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

According to the documentation, the latitude and longitude are in decimels and in kilometers unit.

Use the maximum value from k1dists to find at least 1 neighbor. We round it off and use 62 as cut off to get the matrix. This is similar to the distance based matrix discussion in the slides, where instead of d = 650, we use d = 62km!

NOTE: Ensure to use ceiling/rounded up max value of k1dists! This is to ensure we will capture at least 1 value.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Missing longlat will result in all neighbors being fetched.

### **COMPUTING ADAPTIVE DISTANCE WEIGHT MATRIX**

NOTE: One big difference: We specify the number of neighbors! So, instead of fetching uneven number of neighbors for each point like above, this will make the effor to search further for minimally 6 neighbors:

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```

```{r}
n_comp <- n.comp.nb(wm_d62)
n_comp$nc
```

```{r}
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

## Side by Side Comparison of nearest neighbors vs distance link

```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="1st nearest neighbours")
plot(k1, coords, add=TRUE, col="red", length=0.08)
plot(hunan$geometry, border="lightgrey", main="Distance link")
plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)
```

Four different spatial lagged variables:

-   spatial lag with row-standardized weights,

-   spatial lag as a sum of neighbouring values,

-   spatial window average, and (window functions - includes the diagonal neighbors!)

-   spatial window sum. (window functions - includes the diagonal neighbors & similar to spatial lag as a sum of neighbouring values since it sums up all neighbors)

By default, it will exclude the weights so in order to bring it in we need to be explicit.
